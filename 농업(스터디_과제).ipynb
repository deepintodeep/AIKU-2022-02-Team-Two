{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvWwwv5lMhvD"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gvkqj-d1fQbE"
      },
      "outputs": [],
      "source": [
        "model_save_path = 'model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4km9nHnDg_-n"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goS3Z7EUhI80"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/train.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifeo7T-Lv-gv"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/test.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CldK32_kOmDq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke7AnmtOMVqF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from glob import glob\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import urllib.request\n",
        "import csv\n",
        "import numpy as np\n",
        "from torch.cuda import amp\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "import gc\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "import cv2\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.cuda import amp\n",
        "\n",
        "# Utils\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "import json\n",
        "\n",
        "# Albumentations for augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import timm\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIjZQlVFfmaw"
      },
      "outputs": [],
      "source": [
        "#pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5D_0We3fyFk"
      },
      "outputs": [],
      "source": [
        "#!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3aoErOif7Yj"
      },
      "outputs": [],
      "source": [
        "#import wandb\n",
        "\n",
        "#wandb.init(project=\"my-test-project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR0v4IqSMxMT"
      },
      "outputs": [],
      "source": [
        "config = {'batch':8,\n",
        "        'path': './train/train'}\n",
        "\n",
        "# TODO : ToTensorV2\n",
        "albumentations_transform = A.Compose([\n",
        "        \n",
        "A.Resize(224,224),\n",
        "A.HorizontalFlip(p=0.5),\n",
        "A.RandomBrightnessContrast(p=0.2),\n",
        "ToTensorV2(p =1.0)\n",
        "], p=1.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPTENgsIMzVI"
      },
      "outputs": [],
      "source": [
        "train_json = sorted(glob('train/*/*.json'))\n",
        "\n",
        "labels = []\n",
        "crops = []\n",
        "diseases = []\n",
        "risks = []\n",
        "for i in range(len(train_json)):\n",
        "    with open(train_json[i], 'r') as f:\n",
        "        sample = json.load(f)\n",
        "        crop = sample['annotations']['crop']\n",
        "        disease = sample['annotations']['disease']\n",
        "        risk = sample['annotations']['risk']\n",
        "        label=f\"{crop}_{disease}_{risk}\"\n",
        "        crops.append(crop)\n",
        "        diseases.append(disease)\n",
        "        risks.append(risk)\n",
        "        labels.append(label)\n",
        "\n",
        "label_encoder = sorted(np.unique(labels))\n",
        "label_encoder = {key:value for key,value in zip(label_encoder, range(len(label_encoder)))}\n",
        "\n",
        "label1 = [label_encoder[k] for k in labels]\n",
        "label2 = {}\n",
        "for key, value in label_encoder.items():\n",
        "    label2[key] = value\n",
        "label_decoder = {val:key for key, val in label_encoder.items()}\n",
        "\n",
        "# label_encoder가 decoder처럼 vlaue -> key\n",
        "\n",
        "print(label_decoder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M24w8XlVd_j8"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "], p=1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mKESzhjMU9D"
      },
      "outputs": [],
      "source": [
        "img_path =  sorted(glob('train/*/*.jpg'))\n",
        "label_path = sorted(glob('train/*/*.json'))\n",
        "class PlantImageDataset(Dataset):\n",
        "    def __init__(self, img_path, label_path, transform=None):\n",
        "        self.img_labels = labels\n",
        "        self.transform = transform\n",
        "        self.img_path = img_path\n",
        "        self.label_path = label_path\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = os.path.join(self.img_path[idx])\n",
        "      \n",
        "        image = cv2.imread(path)\n",
        "        \n",
        "        label_path = self.label_path[idx]\n",
        "        # TODO :숫자 반환 \n",
        "        with open(label_path, 'r') as f:\n",
        "          sample = json.load(f)\n",
        "          crop = sample['annotations']['crop']\n",
        "          disease = sample['annotations']['disease']\n",
        "          risk = sample['annotations']['risk']\n",
        "          label=f\"{crop}_{disease}_{risk}\"\n",
        "\n",
        "          label= label_encoder[label]\n",
        "          \n",
        "\n",
        "          if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "dataset = PlantImageDataset(img_path = img_path, label_path = label_path, transform=albumentations_transform)\n",
        "train_dataloader = DataLoader(dataset, batch_size = config['batch'], shuffle = True)\n",
        "valid_dataset = PlantImageDataset(img_path = img_path, label_path = label_path, transform=transform)\n",
        "vaild_dataloader = DataLoader(valid_dataset, batch_size = config['batch'], shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51pPz2MSRTkE"
      },
      "outputs": [],
      "source": [
        "# Albumentations for augmentations\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Augmentations\n",
        "transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "], p=1.)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\n",
        "\n",
        "for x, _ in dataset:\n",
        "\n",
        "    img = x\n",
        "    batch_size = 64\n",
        "    img = np.array(img).T\n",
        "    print(type(img))\n",
        "    print(img.shape)\n",
        "    for i, ax in zip(range(batch_size), axes.flatten()):\n",
        "        ax.imshow(img)\n",
        "        break\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WqJGJs0RZkz"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18\n",
        "\n",
        "backbone = 'resnet18'\n",
        "num_classes = 25\n",
        "emberdder = 512\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.model = timm.create_model(backbone, pretrained=True, num_classes = num_classes)      \n",
        "    \n",
        "    def forward(self, images):\n",
        "        images = self.model(images)\n",
        "        return images\n",
        "\n",
        "model = Model().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcJwpvqZJk2J"
      },
      "outputs": [],
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# class SwinNet(nn.Module):\n",
        "#     def __init__(self, model_name='swin_small_patch4_window7_224', out_features=25,\n",
        "#                  inp_channels=3, pretrained=True):\n",
        "#         super().__init__()\n",
        "#         self.model = timm.create_model(model_name, pretrained=pretrained,\n",
        "#                                        in_chans=inp_channels)\n",
        "#         n_features = self.model.head.in_features\n",
        "#         self.model.head = nn.Linear(n_features, out_features, bias=True)\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         return self.model(x)\n",
        "\n",
        "# model = SwinNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEFAp820RW74"
      },
      "outputs": [],
      "source": [
        "learning_late = 1e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_late)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS7e8EEXYCtW"
      },
      "outputs": [],
      "source": [
        "def accuracy_function(real, pred):\n",
        "    score = f1_score(real, pred, average='macro')\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpYSIRGyRf4h"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, train_dataloader, device, epoch):\n",
        "    model.train()\n",
        "   # wandb.init(project='test', entity = 'suho')\n",
        "    #wandb.watch(model, optimizer, log=\"all\", log_freq=10)\n",
        "\n",
        "    train_loss = 0\n",
        "    train_pred=[]\n",
        "    train_target=[]\n",
        "    best = 0\n",
        "    \n",
        "\n",
        "    for batch in tqdm(train_dataloader):\n",
        "      optimizer.zero_grad()\n",
        "      img = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "      target = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        \n",
        "      logits = model(img.float()/256).to(device)\n",
        "\n",
        "      loss_fn = nn.CrossEntropyLoss()\n",
        "      loss = loss_fn(logits,target)\n",
        "      loss.backward()\n",
        " \n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()/len(train_dataloader)\n",
        "      train_pred += logits.argmax(1).detach().cpu().numpy().tolist()\n",
        "      train_target += target.detach().cpu().numpy().tolist()\n",
        "\n",
        "    train_f1 = accuracy_function(train_target, train_pred)\n",
        "\n",
        "    print(f\"loss : {train_loss:7f}, f1 : {train_f1:7f}\") #acc: {acc:7f}\n",
        "    if train_f1 >= best:\n",
        "      best = train_f1\n",
        "      torch.save(model.state_dict(), 'model.pth')\n",
        "  \n",
        "    return loss, train_f1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAN_0VrXZlTi"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, vaild_dataloader, device, epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    vaild_loss = 0\n",
        "    vaild_pred=[]\n",
        "    vaild_target=[]\n",
        "    best = 0\n",
        "    \n",
        "\n",
        "    for batch in tqdm(vaild_dataloader):\n",
        "      img = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "      target = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        \n",
        "      logits = model(img.float()/256).to(device)\n",
        "\n",
        "      loss_fn = nn.CrossEntropyLoss()\n",
        "      loss = loss_fn(logits,target)\n",
        "      loss.backward()\n",
        "\n",
        "      vaild_loss += loss.item()/len(vaild_dataloader)\n",
        "      vaild_pred += logits.argmax(1).detach().cpu().numpy().tolist()\n",
        "      vaild_target += target.detach().cpu().numpy().tolist()\n",
        "\n",
        "    vaild_f1 = accuracy_function(vaild_target, vaild_pred)\n",
        "\n",
        "    print(f\"loss : {vaild_loss:7f}, f1 : {vaild_f1:7f}\") #acc: {acc:7f}\n",
        "  \n",
        "    return vaild_loss, vaild_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3CTvV4RRjxl"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_one_epoch(model, optimizer, train_dataloader, device, epoch)\n",
        "    valid_one_epoch(model, vaild_dataloader, device, epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ap9iGFCW-re"
      },
      "outputs": [],
      "source": [
        "test_jpg = sorted(glob('test/*/*.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v7bAAx_e0UL"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    ToTensorV2(p =1.0)\n",
        "], p=1.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we7_nPbBXyEa"
      },
      "outputs": [],
      "source": [
        "class custom_dataset(Dataset):\n",
        "    def __init__(self, img_path, transform = None, mode='test'):\n",
        "        self.mode=mode\n",
        "        self.transform = transform\n",
        "        self.img_path = img_path\n",
        "    def __len__(self):\n",
        "        return len(self.img_path)\n",
        "    def __getitem__(self, idx):\n",
        "        path = os.path.join(self.img_path[idx])\n",
        "        image = cv2.imread(path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        return image\n",
        "\n",
        "test_dataset = custom_dataset(test_jpg, transform = transform, mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=1)\n",
        "len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5j_n9-LSxYT"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "model.eval()\n",
        "test_preds=[]\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "      batch[0] = batch[0]\n",
        "      img = torch.tensor(batch[0], device=device)\n",
        "      img = img.unsqueeze(0)\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "          pred = model(img.float()/256)\n",
        "      test_preds += pred.argmax(1).detach().cpu().numpy().tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Qv23rqtpr9F"
      },
      "outputs": [],
      "source": [
        "test_pred = [str(label_decoder[i]) for i in test_preds]\n",
        "len(test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2leIYWzoBsH"
      },
      "outputs": [],
      "source": [
        "submission_template = pd.read_csv('sample_submission.csv')\n",
        "submission_template.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yR-L1weqoOdr"
      },
      "outputs": [],
      "source": [
        "submission = submission_template.copy()\n",
        "submission['label'] = test_pred\n",
        "print(len(submission))\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5_j8sn8wgR4"
      },
      "outputs": [],
      "source": [
        "submission_file_name = 'f1f1.csv'\n",
        "submission.to_csv(submission_file_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2EmJzwwPFDq"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}