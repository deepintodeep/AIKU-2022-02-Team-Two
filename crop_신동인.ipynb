{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rp9ZgRProltT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fe28dd-5ed0-43a1-d42a-463752521d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThbgyG4uZeIF",
        "outputId": "9d58c955-5e75-479c-8c38-63673b2f8e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->timm) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.10.1 timm-0.6.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "B7c05GVA3GUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from glob import glob\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import urllib.request\n",
        "import csv\n",
        "import numpy as np\n",
        "#from einops import rearrange, reduce, repeat\n",
        "from torch.cuda import amp\n",
        "from tqdm import tqdm\n",
        "#import wandb\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "import gc\n",
        "import os\n",
        "#from icecream import ic\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "import cv2\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Utils\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "import timm\n",
        "\n",
        "import json\n",
        "\n",
        "# Albumentations for augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# For colored terminal text\n",
        "#from colorama import Fore, Back, Style\n",
        "#c_ = Fore.CYAN\n",
        "#sr_ = Style.RESET_ALL\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "nQ91gDJA3aM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENV\n"
      ],
      "metadata": {
        "id": "8rQm4Gt73vFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SET SEED"
      ],
      "metadata": {
        "id": "Nt4HgWua37qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = dict(\n",
        "    nickname = 'convnext_small',\n",
        "    seed=42,\n",
        "    backbone='convnext_small',\n",
        "    embedder=None,\n",
        "    train_batch_size=8,\n",
        "    valid_batch_size=16,\n",
        "    img_size=224,\n",
        "    num_epochs=50,\n",
        "    early_stopping=False,\n",
        "    early_stopping_step=5,\n",
        "    learning_rate=1e-4,\n",
        "    scheduler='CosineAnnealingLR',\n",
        "    min_lr=1e-6,\n",
        "    T_max=100,\n",
        "    num_classes=25,\n",
        "    weight_decay=1e-6,\n",
        "    device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
        "    competition='lg',\n",
        "    _wandb_kernel='deb'\n",
        ")"
      ],
      "metadata": {
        "id": "WASgK54MaTHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentations"
      ],
      "metadata": {
        "id": "Yl8KtTAR4HPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentations 파트에서 resize,  augmentations, totensorV2 를 albumentation을 이용하여 객체 전달 후 getitem에서 전달해주기\n",
        "# 사이즈가 정해져야 모델이 학습할 수 있음.\n",
        "\n",
        "transform = A.Compose([\n",
        "      A.Resize(224,224),\n",
        "      A.Normalize(),\n",
        "      ToTensorV2()\n",
        "])\n"
      ],
      "metadata": {
        "id": "llXg60tP4K41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the Data"
      ],
      "metadata": {
        "id": "o8IxHmdR4BvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.utils.contexts import NoOpContext\n",
        "class CustomImageDataset(Dataset) :\n",
        "  def __init__(self, path, transform=None) :\n",
        "    self.crops = []\n",
        "    self.diseases = []\n",
        "    self.risks = []\n",
        "    self.label = {}\n",
        "    labels = []\n",
        "    \n",
        "    self.json_list = sorted(glob(path+'crop_data/train/*/*.json'))\n",
        "    self.jpg_list = sorted(glob(path+'crop_data/train/*/*.jpg'))\n",
        "    \n",
        "    for i in self.json_list :\n",
        "      with open(i, 'r') as f :\n",
        "        json_dict = json.load(f) # json_dict[\"annotations\"][\"crop\"], json_dict[\"annotations\"][\"disease\"], json_dict[\"annotations\"][\"risk\"] \n",
        "        crop = json_dict[\"annotations\"][\"crop\"]\n",
        "        disease = json_dict[\"annotations\"][\"disease\"]\n",
        "        risk = json_dict[\"annotations\"][\"risk\"]\n",
        "      self.crops.append(crop)\n",
        "      self.diseases.append(disease)\n",
        "      self.risks.append(risk)\n",
        "      labels.append(f\"{crop}_{disease}_{risk}\")\n",
        "    np_label = np.array(labels)\n",
        "    unique_label = np.unique(np_label)\n",
        "    np.sort(unique_label)\n",
        "    for x in range(len(unique_label.tolist())) :\n",
        "      self.label[unique_label[x]] = x\n",
        "    self.transform=transform\n",
        "      \n",
        "      \n",
        "      \n",
        "  def __len__(self) :\n",
        "      return len(self.json_list)\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "      #tf_toTensor = ToTensor()\n",
        "\n",
        "      img = cv2.imread(self.jpg_list[idx])\n",
        "      #img_tensor = tf_toTensor(img)\n",
        "      transformed = transform(image = img)\n",
        "      img_tensor = transformed[\"image\"]\n",
        "      label_idx = f'{self.crops[idx]}_{self.diseases[idx]}_{self.risks[idx]}'\n",
        "      return img_tensor, self.label[label_idx]\n",
        "          \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "fz3KH-KH30Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1hgi5Ww-7nsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "3xMvI8c74LcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "k6PXp-5f4yVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomImageDataset('/content/drive/MyDrive/',transform = transform)"
      ],
      "metadata": {
        "id": "d_e-jAlH4Oiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(dataset.jpg_list[100])\n",
        "print(img[253][234][1])"
      ],
      "metadata": {
        "id": "0GVePgl45c2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34282c26-88ea-4de0-e91c-615eda1c3d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.shape)\n",
        "print(dataset[0])\n",
        "print(len(dataset.label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLyGifX4yqop",
        "outputId": "bb674316-2eaf-48d9-ee0e-dc0443ff2c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 384, 3)\n",
            "(tensor([[[-1.1589, -1.5014, -1.6898,  ..., -1.3987, -1.6042, -1.0219],\n",
            "         [-1.1075, -1.1589, -1.6384,  ..., -0.5253, -1.3130, -1.0562],\n",
            "         [-1.1247, -1.1247, -1.3987,  ..., -1.8439, -1.5528, -1.3644],\n",
            "         ...,\n",
            "         [ 1.1700,  1.2043,  1.1187,  ..., -1.8097, -1.8953, -1.8268],\n",
            "         [ 1.1700,  1.1700,  1.1358,  ..., -1.6727, -1.8097, -1.7412],\n",
            "         [ 1.2043,  1.1872,  1.0331,  ..., -1.6898, -1.7583, -1.7412]],\n",
            "\n",
            "        [[ 0.0476, -0.0749, -0.1099,  ...,  1.4132,  0.9055,  1.1681],\n",
            "         [ 0.1176,  0.1877, -0.1625,  ...,  1.4832,  0.6078,  0.7304],\n",
            "         [ 0.0651,  0.1176, -0.0924,  ..., -0.0924,  0.2052,  0.2927],\n",
            "         ...,\n",
            "         [ 1.2381,  1.2381,  1.1856,  ..., -0.3725, -0.4426, -0.3550],\n",
            "         [ 1.2031,  1.2031,  1.1506,  ..., -0.1800, -0.3200, -0.3025],\n",
            "         [ 1.2556,  1.2206,  1.0630,  ..., -0.1450, -0.2675, -0.3200]],\n",
            "\n",
            "        [[-0.6367, -0.8458, -0.8981,  ...,  0.6356,  0.1476,  0.4614],\n",
            "         [-0.5670, -0.5147, -0.9330,  ...,  0.7925, -0.0790,  0.0605],\n",
            "         [-0.5844, -0.5495, -0.7936,  ..., -0.7413, -0.4624, -0.3927],\n",
            "         ...,\n",
            "         [ 0.8971,  0.8971,  0.8622,  ..., -1.0724, -1.1421, -1.0201],\n",
            "         [ 0.8448,  0.8448,  0.8448,  ..., -0.8807, -1.0201, -0.9678],\n",
            "         [ 0.8274,  0.8622,  0.7402,  ..., -0.8633, -0.9678, -0.9853]]]), 9)\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(dataset[0]) # dataset 객체가 image tensor 와 해당하는 label을 반환\n",
        "print(dataset.jpg_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys-WswLRzLrK",
        "outputId": "48bbc86d-fef7-4598-8c7b-4753710f9005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/crop_data/train/10027/10027.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(dataset.label['3_b7_1']) # key-value 잘 대응되는지 확인 완료"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6QzRNlz7f3h",
        "outputId": "f46a673a-4ddb-4f1a-a9b6-87f0b1ff03cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset, batch_size = 8, shuffle = True)"
      ],
      "metadata": {
        "id": "hhAfv4h6-AKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0][0].shape)\n",
        "print(dataset[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpqjY3KCFKRG",
        "outputId": "4ebf38a9-ad78-422a-cb37-bb0e160daf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "hVdaJxmlYBR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module) :\n",
        "  def __init__(self, backbone, embedder, pretrained = True) :\n",
        "    super(Model, self).__init__()\n",
        "    self.backbone = timm.create_model(backbone, \n",
        "                                      pretrained = pretrained)\n",
        "    self.backbone.reset_classifier(0)\n",
        "\n",
        "  def forward(self, images) :\n",
        "    \n",
        "    output = self.backbone(images)\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "j4xyqlLKYF_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((CONFIG['train_batch_size'], 3, CONFIG['img_size'], CONFIG['img_size']))\n",
        "net = Model(CONFIG['backbone'], CONFIG['embedder'])\n",
        "output = net(X)\n"
      ],
      "metadata": {
        "id": "9BekTq6vhRJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyCYP-Tui6Jf",
        "outputId": "d5acbdf8-677e-4706-ec67-b62b610a304a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTh7SgwvjPbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}